import streamlit as st
from transformers import pipeline

# è¨­å®šé é¢æ¨™é¡Œèˆ‡åœ–ç¤º
st.set_page_config(page_title="AI vs Human Detector", page_icon="ğŸ¤–")

st.title("ğŸ¤– AI æ–‡æœ¬åµæ¸¬å™¨")
st.markdown("è«‹è¼¸å…¥ä¸€æ®µè‹±æ–‡æ–‡ç« ï¼Œæ¨¡å‹å°‡åˆ¤æ–·é€™æ®µæ–‡å­—æ˜¯ç”± **AI ç”Ÿæˆ** é‚„æ˜¯ **äººé¡æ’°å¯«**ã€‚")

# å´é‚Šæ¬„èªªæ˜
with st.sidebar:
    st.header("é—œæ–¼æ¨¡å‹")
    st.info("æœ¬å·¥å…·ä½¿ç”¨ Hugging Face çš„ Transformers åº«ï¼Œè¼‰å…¥ `roberta-base-openai-detector` æ¨¡å‹é€²è¡Œæ¨è«–ã€‚")
    st.markdown("---")
    st.write("Created for HW5 - Advanced Topic")

# 1. è¼‰å…¥æ¨¡å‹
@st.cache_resource
def load_model():
    classifier = pipeline("text-classification", model="roberta-base-openai-detector")
    return classifier

try:
    with st.spinner('æ­£åœ¨è¼‰å…¥ AI åµæ¸¬æ¨¡å‹...ï¼ˆé¦–æ¬¡åŸ·è¡Œéœ€ä¸‹è¼‰æ¨¡å‹ï¼Œç´„éœ€ 1-2 åˆ†é˜ï¼‰'):
        pipe = load_model()
    model_loaded = True
except Exception as e:
    st.error(f"æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
    model_loaded = False

# 2. ä½¿ç”¨è€…ä»‹é¢ - æ–‡å­—è¼¸å…¥
user_input = st.text_area("åœ¨æ­¤è²¼ä¸Šè¦æª¢æ¸¬çš„æ–‡æœ¬ (ç›®å‰æ¨¡å‹å°è‹±æ–‡æ”¯æ´åº¦æœ€ä½³):", height=200)

# 3. åŸ·è¡Œåµæ¸¬
if st.button("é–‹å§‹åˆ†æ ğŸš€") and model_loaded:
    if not user_input.strip():
        st.warning("è«‹å…ˆè¼¸å…¥æ–‡å­—ï¼")
    else:
        with st.spinner('AI æ­£åœ¨è®€å–ä¸¦åˆ†æç‰¹å¾µ...'):
            # --- ä¿®æ­£é–‹å§‹ ---
            # åŠ å…¥ truncation=True èˆ‡ max_length=512 è§£æ±ºé•·åº¦å ±éŒ¯å•é¡Œ
            results = pipe(user_input, top_k=None, truncation=True, max_length=512)
            # --- ä¿®æ­£çµæŸ ---
            
            # æ•´ç†æ•¸æ“š
            scores = {item['label']: item['score'] for item in results}
            
            # åŸå§‹æ¨¡å‹æ¨™ç±¤å®šç¾©ï¼š 'Real' = Human, 'Fake' = AI
            ai_score = scores.get('Fake', 0.0)
            human_score = scores.get('Real', 0.0)

        # 4. é¡¯ç¤ºçµæœ
        st.subheader("ğŸ“Š åˆ†æçµæœ")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.metric(label="AI ç”Ÿæˆæ©Ÿç‡", value=f"{ai_score:.2%}")
            st.progress(ai_score)
            
        with col2:
            st.metric(label="äººé¡æ’°å¯«æ©Ÿç‡", value=f"{human_score:.2%}")
            st.progress(human_score, "primary")

        st.divider()
        if ai_score > 0.8:
            st.error("ğŸš¨ åˆ¤å®šçµæœï¼šé€™æ¥µå¤§æ©Ÿç‡æ˜¯ç”± **AI (å¦‚ ChatGPT)** ç”Ÿæˆçš„å…§å®¹ã€‚")
        elif ai_score > 0.5:
            st.warning("âš ï¸ åˆ¤å®šçµæœï¼šé€™æ®µæ–‡å­—å¸¶æœ‰ **AI ç”Ÿæˆç‰¹å¾µ**ï¼Œå¯èƒ½æ˜¯æ··åˆæ’°å¯«ã€‚")
        else:
            st.success("âœ… åˆ¤å®šçµæœï¼šé€™çœ‹èµ·ä¾†åƒæ˜¯ **äººé¡ (Human)** æ’°å¯«çš„å…§å®¹ã€‚")

        with st.expander("æŸ¥çœ‹åŸå§‹æ•¸æ“š"):
            st.json(results)
